{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Resources/NVMeProblems/nvme_increasingCPUs_flexibleSST/45GB/StorageMaterial.NVMeSSD/4CPU/64MB\n",
      "Resources/NVMeProblems/nvme_increasingCPUs_flexibleSST/45GB/StorageMaterial.NVMeSSD/8CPU/64MB\n",
      "Resources/NVMeProblems/nvme_increasingCPUs_flexibleSST/45GB/StorageMaterial.NVMeSSD/12CPU/64MB\n",
      "['Resources/NVMeProblems/nvme_increasingCPUs_flexibleSST/45GB/StorageMaterial.NVMeSSD/4CPU/64MB/LOG_1290', 'Resources/NVMeProblems/nvme_increasingCPUs_flexibleSST/45GB/StorageMaterial.NVMeSSD/8CPU/64MB/LOG_1330', 'Resources/NVMeProblems/nvme_increasingCPUs_flexibleSST/45GB/StorageMaterial.NVMeSSD/12CPU/64MB/LOG_1310']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import  glob\n",
    "\n",
    "def log_file_path(memtable_size,cpu_count,storage_device=\"StorageMaterial.NVMeSSD\",prefix=\"Resources/\"):\n",
    "    target_path = prefix\n",
    "    \n",
    "    target_path += \"%s/%s/%s\" % (storage_device,\n",
    "               str(cpu_count)+\"CPU\",\n",
    "               str(memtable_size)+\"MB\")\n",
    "    return target_path\n",
    "# you can test it like this\n",
    "\n",
    "def find_log_file(log_dir):\n",
    "    log_file = [filename for filename in glob.glob(\n",
    "                log_dir+\"/**\") if \"LOG\" in filename][0]    \n",
    "    return log_file\n",
    "\n",
    "dir_pres = [\"nvme_increasingCPUs_flexibleSST\"]\n",
    "prefixes = [\"Resources/NVMeProblems/\" + dir_pre + \"/45GB/\" for dir_pre in dir_pres]\n",
    "materials = ['NVMeSSD']\n",
    "cpu_count_array = [4,8,12]\n",
    "memtable_size_array = [64]\n",
    "\n",
    "log_files = []\n",
    "\n",
    "for prefix in prefixes:\n",
    "    for material in materials: \n",
    "        for cpu_count in cpu_count_array:\n",
    "            for memtable_size in memtable_size_array:\n",
    "                log_dir = log_file_path(memtable_size,cpu_count,\n",
    "                                      \"StorageMaterial.\"+material,prefix)\n",
    "                log_files.append(find_log_file(log_dir))\n",
    "\n",
    "print(log_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Analyze the data from increasing CPU"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "dict_keys(['compaction_started', 'compaction_finished'])\n",
      "dict_keys(['compaction_started', 'compaction_finished'])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "job_id_dict = {}\n",
    "event_row_dict = {}\n",
    "EVENTS_NEED_COLLECTED = ['compaction_started','compaction_finished']\n",
    "\n",
    "\n",
    "def handle_single_file(file):\n",
    "    job_dict = {}\n",
    "    event_dict = {}\n",
    "    \n",
    "    for event in EVENTS_NEED_COLLECTED:\n",
    "        event_dict[event] = {}\n",
    "        job_dict[event] = []\n",
    "        \n",
    "    file_content = open(file,\"r\").readlines()\n",
    "    \n",
    "    for line in file_content:\n",
    "        line = re.search('(\\{.+\\})', line)\n",
    "        if line:\n",
    "            try:\n",
    "                log_row = json.loads(line[0])\n",
    "                job_id = int(log_row['job'])\n",
    "                current_event = log_row['event']\n",
    "                if current_event in EVENTS_NEED_COLLECTED:\n",
    "                    if job_id not in job_dict[current_event]:\n",
    "                        event_dict[current_event][job_id] = [log_row]\n",
    "                        job_dict[current_event].append(job_id)\n",
    "                    else:\n",
    "                        event_dict[current_event][job_id].append(log_row)\n",
    "                        print(log_row)\n",
    "            except json.decoder.JSONDecodeError:\n",
    "                pass\n",
    "    return job_dict,event_dict\n",
    "\n",
    "job_id_dict,event_row_dict = handle_single_file(log_files[0]) \n",
    "\n",
    "print(job_id_dict.keys())\n",
    "print(event_row_dict.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Resources+NVMeProblems+nvme_increasingCPUs_flexibleSST+45GB+StorageMaterial.NVMeSSD+4CPU+64MB+LOG_1290\n",
      "Average Compaction Latency 5965902.233576642\n",
      "Average CPU Time 5965902.233576642\n",
      "Resources+NVMeProblems+nvme_increasingCPUs_flexibleSST+45GB+StorageMaterial.NVMeSSD+8CPU+64MB+LOG_1330\n",
      "Average Compaction Latency 6010740.337860781\n",
      "Average CPU Time 6010740.337860781\n",
      "Resources+NVMeProblems+nvme_increasingCPUs_flexibleSST+45GB+StorageMaterial.NVMeSSD+12CPU+64MB+LOG_1310\n",
      "Average Compaction Latency 6426537.803056027\n",
      "Average CPU Time 6426537.803056027\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from statistics import mean\n",
    "\n",
    "def cpu_time_plot_single_file(result_prefix,job_dict,event_dict):\n",
    "    compaction_reason_dict = {}\n",
    "    compaction_latencies = []\n",
    "    compaction_cpu_time = []\n",
    "    # group the compaction according to the reason\n",
    "    for compaction_job in job_dict['compaction_started']:    \n",
    "        compaction_start_row = event_dict['compaction_started'][compaction_job][0]\n",
    "        compaction_finish_row = event_dict['compaction_finished'][compaction_job][0]\n",
    "        current_reason = compaction_start_row['compaction_reason']\n",
    "        \n",
    "        if current_reason not in compaction_reason_dict:\n",
    "            compaction_reason_dict[current_reason] = []\n",
    "        else:\n",
    "            compaction_reason_dict[current_reason].append(compaction_job)\n",
    "        compaction_latencies.append(compaction_finish_row['compaction_time_micros'])\n",
    "        compaction_cpu_time.append(compaction_finish_row['compaction_time_cpu_micros'])\n",
    "    print(result_prefix)\n",
    "    print(\"Average Compaction Latency\", mean(compaction_latencies))\n",
    "    print(\"Average CPU Time\", mean(compaction_latencies))\n",
    "    print(\"Average \")\n",
    "        \n",
    "    # fig = plt.figure(figsize=(16, 9))\n",
    "    # fig.suptitle(\"Overall Time\")\n",
    "\n",
    "for log_file in log_files:\n",
    "    current_job_dict, current_event_dict = handle_single_file(log_file)\n",
    "    figure_prefix = log_file.replace(\"/\",\"+\")\n",
    "    cpu_time_plot_single_file(str(figure_prefix),current_job_dict,current_event_dict)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "According to the above result, adding CPUs will slightly increase the compaction time, but it won't hurt too much on NVMe SSD.\n",
    "\n",
    "This might be explained by NVMe behaves better with deep queue depth"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}